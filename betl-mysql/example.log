[ERROR :2016-01-22 18:29:14],[com.betl.option.ConfOption] - config instince failed
org.apache.commons.cli.MissingOptionException: Missing required option: P
	at org.apache.commons.cli.Parser.checkRequiredOptions(Parser.java:299)
	at org.apache.commons.cli.Parser.parse(Parser.java:231)
	at org.apache.commons.cli.Parser.parse(Parser.java:85)
	at com.betl.option.ConfOption.getConf(ConfOption.java:54)
	at com.betl.mysql.mr.MysqlToHdfs.main(MysqlToHdfs.java:32)
[ INFO :2016-01-22 18:29:57],[com.betl.option.ConfOption] - the config file public.xml is load sucess from external
[ INFO :2016-01-22 18:29:57],[com.betl.option.ConfOption] - the config file sinanews-schema.xml is load sucess from external
[ INFO :2016-01-22 18:29:58],[com.betl.option.ConfOption] - Print Configuration [-D key=value]: 
[ INFO :2016-01-22 18:30:33],[com.betl.option.ConfOption] - the config file public.xml is load sucess from external
[ INFO :2016-01-22 18:30:33],[com.betl.option.ConfOption] - the config file sinanews-schema.xml is load sucess from external
[ INFO :2016-01-22 18:30:33],[com.betl.option.ConfOption] - Print Configuration [-D key=value]: 
[ INFO :2016-01-22 18:30:44],[com.betl.option.ConfOption] - the config file public.xml is load sucess from external
[ INFO :2016-01-22 18:30:44],[com.betl.option.ConfOption] - the config file sinanews-schema.xml is load sucess from external
[ INFO :2016-01-22 18:30:44],[com.betl.option.ConfOption] - Print Configuration [-D key=value]: 
[ INFO :2016-01-22 18:33:57],[com.betl.option.ConfOption] - the config file public.xml is load sucess from external
[ INFO :2016-01-22 18:33:57],[com.betl.option.ConfOption] - the config file sinanews-schema.xml is load sucess from external
[ INFO :2016-01-22 18:33:57],[com.betl.option.ConfOption] - Print Configuration [-D key=value]: 
[ INFO :2016-01-22 18:34:07],[org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
[ INFO :2016-01-22 18:34:07],[org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
[ WARN :2016-01-22 18:34:13],[org.apache.hadoop.mapreduce.JobSubmitter] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
[ WARN :2016-01-22 18:34:13],[org.apache.hadoop.mapreduce.JobSubmitter] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[ INFO :2016-01-22 18:34:13],[org.apache.hadoop.mapreduce.JobSubmitter] - Cleaning up the staging area file:/tmp/hadoop-Administrator/mapred/staging/hdfs86543407/.staging/job_local86543407_0001
[ INFO :2016-01-22 18:36:16],[com.betl.option.ConfOption] - the config file public.xml is load sucess from external
[ INFO :2016-01-22 18:36:16],[com.betl.option.ConfOption] - the config file sinanews-schema.xml is load sucess from external
[ INFO :2016-01-22 18:36:16],[com.betl.option.ConfOption] - Print Configuration [-D key=value]: 
[ INFO :2016-01-22 18:36:18],[org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
[ INFO :2016-01-22 18:36:18],[org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
[ WARN :2016-01-22 18:36:19],[org.apache.hadoop.mapreduce.JobSubmitter] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
[ WARN :2016-01-22 18:36:19],[org.apache.hadoop.mapreduce.JobSubmitter] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[ INFO :2016-01-22 18:36:19],[org.apache.hadoop.mapreduce.JobSubmitter] - Cleaning up the staging area file:/tmp/hadoop-Administrator/mapred/staging/hdfs1862568399/.staging/job_local1862568399_0001
[ INFO :2016-01-22 18:37:41],[com.betl.option.ConfOption] - the config file public.xml is load sucess from external
[ INFO :2016-01-22 18:37:41],[com.betl.option.ConfOption] - the config file sinanews-schema.xml is load sucess from external
[ INFO :2016-01-22 18:37:42],[com.betl.option.ConfOption] - Print Configuration [-D key=value]: 
[ INFO :2016-01-22 18:37:44],[org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
[ INFO :2016-01-22 18:37:44],[org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
[ WARN :2016-01-22 18:37:44],[org.apache.hadoop.mapreduce.JobSubmitter] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
[ WARN :2016-01-22 18:37:44],[org.apache.hadoop.mapreduce.JobSubmitter] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[ INFO :2016-01-22 18:37:44],[org.apache.hadoop.mapreduce.JobSubmitter] - Cleaning up the staging area file:/tmp/hadoop-Administrator/mapred/staging/hdfs123205946/.staging/job_local123205946_0001
[ INFO :2016-01-22 18:38:32],[com.betl.option.ConfOption] - the config file public.xml is load sucess from external
[ INFO :2016-01-22 18:38:32],[com.betl.option.ConfOption] - the config file sinanews-schema.xml is load sucess from external
[ INFO :2016-01-22 18:38:32],[com.betl.option.ConfOption] - Print Configuration [-D key=value]: 
[ INFO :2016-01-22 18:39:57],[org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
[ INFO :2016-01-22 18:39:57],[org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
[ WARN :2016-01-22 18:39:59],[org.apache.hadoop.mapreduce.JobSubmitter] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
[ WARN :2016-01-22 18:39:59],[org.apache.hadoop.mapreduce.JobSubmitter] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[ INFO :2016-01-22 18:40:00],[org.apache.hadoop.mapreduce.JobSubmitter] - Cleaning up the staging area file:/tmp/hadoop-Administrator/mapred/staging/hdfs509184068/.staging/job_local509184068_0001
[ INFO :2016-01-22 18:41:39],[com.betl.option.ConfOption] - the config file public.xml is load sucess from external
[ INFO :2016-01-22 18:41:39],[com.betl.option.ConfOption] - the config file sinanews-schema.xml is load sucess from external
[ INFO :2016-01-22 18:41:39],[com.betl.option.ConfOption] - Print Configuration [-D key=value]: 
[ INFO :2016-01-22 18:41:46],[org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
[ INFO :2016-01-22 18:41:46],[org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
[ WARN :2016-01-22 18:41:48],[org.apache.hadoop.mapreduce.JobSubmitter] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
[ WARN :2016-01-22 18:41:48],[org.apache.hadoop.mapreduce.JobSubmitter] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[ INFO :2016-01-22 18:41:48],[org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
[ INFO :2016-01-22 18:41:48],[org.apache.hadoop.conf.Configuration.deprecation] - mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
[ INFO :2016-01-22 18:41:49],[org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local202789685_0001
[ WARN :2016-01-22 18:41:49],[org.apache.hadoop.conf.Configuration] - file:/tmp/hadoop-Administrator/mapred/staging/hdfs202789685/.staging/job_local202789685_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[ WARN :2016-01-22 18:41:49],[org.apache.hadoop.conf.Configuration] - file:/tmp/hadoop-Administrator/mapred/staging/hdfs202789685/.staging/job_local202789685_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[ WARN :2016-01-22 18:41:49],[org.apache.hadoop.conf.Configuration] - file:/tmp/hadoop-Administrator/mapred/local/localRunner/hdfs/job_local202789685_0001/job_local202789685_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[ WARN :2016-01-22 18:41:49],[org.apache.hadoop.conf.Configuration] - file:/tmp/hadoop-Administrator/mapred/local/localRunner/hdfs/job_local202789685_0001/job_local202789685_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[ INFO :2016-01-22 18:41:49],[org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
[ INFO :2016-01-22 18:41:49],[org.apache.hadoop.mapreduce.Job] - Running job: job_local202789685_0001
[ INFO :2016-01-22 18:41:49],[org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
[ INFO :2016-01-22 18:41:50],[org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[ INFO :2016-01-22 18:41:50],[org.apache.hadoop.mapreduce.Job] - Job job_local202789685_0001 running in uber mode : false
[ INFO :2016-01-22 18:41:51],[org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
[ INFO :2016-01-22 18:41:51],[org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local202789685_0001_m_000000_0
[ INFO :2016-01-22 18:41:51],[org.apache.hadoop.mapreduce.Job] -  map 0% reduce 0%
[ INFO :2016-01-22 18:41:51],[org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
[ INFO :2016-01-22 18:41:55],[org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@101cd25f
[ INFO :2016-01-22 18:41:55],[org.apache.hadoop.mapred.MapTask] - Processing split: org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit@4c769a3
[ INFO :2016-01-22 18:41:55],[org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[ INFO :2016-01-22 18:41:55],[org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
[ INFO :2016-01-22 18:41:55],[org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
[ INFO :2016-01-22 18:41:55],[org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
[ INFO :2016-01-22 18:41:55],[org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
[ INFO :2016-01-22 18:41:55],[org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
[ INFO :2016-01-22 18:41:56],[org.apache.hadoop.mapred.LocalJobRunner] - 
[ INFO :2016-01-22 18:41:56],[org.apache.hadoop.mapred.MapTask] - Starting flush of map output
[ INFO :2016-01-22 18:41:56],[org.apache.hadoop.mapred.MapTask] - Spilling map output
[ INFO :2016-01-22 18:41:56],[org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 3575118; bufvoid = 104857600
[ INFO :2016-01-22 18:41:56],[org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26211600(104846400); length = 2797/6553600
[ INFO :2016-01-22 18:41:57],[org.apache.hadoop.mapred.MapTask] - Finished spill 0
[ INFO :2016-01-22 18:41:57],[org.apache.hadoop.mapred.Task] - Task:attempt_local202789685_0001_m_000000_0 is done. And is in the process of committing
[ INFO :2016-01-22 18:41:57],[org.apache.hadoop.mapred.LocalJobRunner] - map
[ INFO :2016-01-22 18:41:57],[org.apache.hadoop.mapred.Task] - Task 'attempt_local202789685_0001_m_000000_0' done.
[ INFO :2016-01-22 18:41:57],[org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local202789685_0001_m_000000_0
[ INFO :2016-01-22 18:41:57],[org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
[ INFO :2016-01-22 18:41:57],[org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
[ INFO :2016-01-22 18:41:57],[org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local202789685_0001_r_000000_0
[ INFO :2016-01-22 18:41:57],[org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
[ INFO :2016-01-22 18:41:57],[org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@45cdfe2
[ INFO :2016-01-22 18:41:58],[org.apache.hadoop.mapreduce.Job] -  map 100% reduce 0%
[ INFO :2016-01-22 18:41:58],[org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@88dfd83
[ INFO :2016-01-22 18:41:59],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=655097856, maxSingleShuffleLimit=163774464, mergeThreshold=432364608, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[ INFO :2016-01-22 18:41:59],[org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local202789685_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[ INFO :2016-01-22 18:41:59],[org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local202789685_0001_m_000000_0 decomp: 3577919 len: 3577923 to MEMORY
[ INFO :2016-01-22 18:42:00],[org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 3577919 bytes from map-output for attempt_local202789685_0001_m_000000_0
[ INFO :2016-01-22 18:42:00],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 3577919, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3577919
[ INFO :2016-01-22 18:42:00],[org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
[ INFO :2016-01-22 18:42:00],[org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
[ INFO :2016-01-22 18:42:00],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[ INFO :2016-01-22 18:42:01],[org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
[ INFO :2016-01-22 18:42:01],[org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 3577907 bytes
[ INFO :2016-01-22 18:42:01],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 3577919 bytes to disk to satisfy reduce memory limit
[ INFO :2016-01-22 18:42:01],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 3577923 bytes from disk
[ INFO :2016-01-22 18:42:01],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
[ INFO :2016-01-22 18:42:01],[org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
[ INFO :2016-01-22 18:42:01],[org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 3577907 bytes
[ INFO :2016-01-22 18:42:01],[org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
[ INFO :2016-01-22 18:42:02],[org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[ INFO :2016-01-22 18:42:03],[org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
[ INFO :2016-01-22 18:42:04],[org.apache.hadoop.mapreduce.Job] -  map 100% reduce 67%
[ INFO :2016-01-22 18:42:06],[org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
[ INFO :2016-01-22 18:42:07],[org.apache.hadoop.mapreduce.Job] -  map 100% reduce 100%
[ INFO :2016-01-22 18:42:09],[org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
[ INFO :2016-01-22 18:42:10],[org.apache.hadoop.mapred.Task] - Task:attempt_local202789685_0001_r_000000_0 is done. And is in the process of committing
[ INFO :2016-01-22 18:42:10],[org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
[ INFO :2016-01-22 18:42:10],[org.apache.hadoop.mapred.Task] - Task attempt_local202789685_0001_r_000000_0 is allowed to commit now
[ INFO :2016-01-22 18:42:10],[org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local202789685_0001_r_000000_0' to hdfs://10.111.32.202:8020/mysql/raw/spiderdb/sinanews/_temporary/0/task_local202789685_0001_r_000000
[ INFO :2016-01-22 18:42:10],[org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
[ INFO :2016-01-22 18:42:10],[org.apache.hadoop.mapred.Task] - Task 'attempt_local202789685_0001_r_000000_0' done.
[ INFO :2016-01-22 18:42:10],[org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local202789685_0001_r_000000_0
[ INFO :2016-01-22 18:42:10],[org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
[ INFO :2016-01-22 18:42:11],[org.apache.hadoop.mapreduce.Job] - Job job_local202789685_0001 completed successfully
[ INFO :2016-01-22 18:42:11],[org.apache.hadoop.mapreduce.Job] - Counters: 38
	File System Counters
		FILE: Number of bytes read=7156126
		FILE: Number of bytes written=11201679
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=3568119
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=700
		Map output records=700
		Map output bytes=3575118
		Map output materialized bytes=3577923
		Input split bytes=78
		Combine input records=0
		Combine output records=0
		Reduce input groups=700
		Reduce shuffle bytes=3577923
		Reduce input records=700
		Reduce output records=700
		Spilled Records=1400
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=56
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=584056832
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=3568119
[ INFO :2016-01-22 18:45:08],[com.betl.option.ConfOption] - the config file public.xml is load sucess from external
[ INFO :2016-01-22 18:45:08],[com.betl.option.ConfOption] - the config file sinanews-schema.xml is load sucess from external
[ INFO :2016-01-22 18:45:09],[com.betl.option.ConfOption] - Print Configuration [-D key=value]: 
[ INFO :2016-01-22 18:45:55],[org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
[ INFO :2016-01-22 18:45:55],[org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
[ WARN :2016-01-22 18:45:57],[org.apache.hadoop.mapreduce.JobSubmitter] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
[ WARN :2016-01-22 18:45:57],[org.apache.hadoop.mapreduce.JobSubmitter] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[ INFO :2016-01-22 18:45:57],[org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
[ INFO :2016-01-22 18:45:57],[org.apache.hadoop.conf.Configuration.deprecation] - mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
[ INFO :2016-01-22 18:45:58],[org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local1425981758_0001
[ WARN :2016-01-22 18:45:58],[org.apache.hadoop.conf.Configuration] - file:/tmp/hadoop-Administrator/mapred/staging/hdfs1425981758/.staging/job_local1425981758_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[ WARN :2016-01-22 18:45:58],[org.apache.hadoop.conf.Configuration] - file:/tmp/hadoop-Administrator/mapred/staging/hdfs1425981758/.staging/job_local1425981758_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[ WARN :2016-01-22 18:45:58],[org.apache.hadoop.conf.Configuration] - file:/tmp/hadoop-Administrator/mapred/local/localRunner/hdfs/job_local1425981758_0001/job_local1425981758_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[ WARN :2016-01-22 18:45:58],[org.apache.hadoop.conf.Configuration] - file:/tmp/hadoop-Administrator/mapred/local/localRunner/hdfs/job_local1425981758_0001/job_local1425981758_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[ INFO :2016-01-22 18:45:58],[org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
[ INFO :2016-01-22 18:45:58],[org.apache.hadoop.mapreduce.Job] - Running job: job_local1425981758_0001
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1425981758_0001_m_000000_0
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@57e12237
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.MapTask] - Processing split: org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit@1b070726
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
[ INFO :2016-01-22 18:45:59],[org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapreduce.Job] - Job job_local1425981758_0001 running in uber mode : false
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapreduce.Job] -  map 0% reduce 0%
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.LocalJobRunner] - 
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.MapTask] - Starting flush of map output
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.MapTask] - Spilling map output
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 3575118; bufvoid = 104857600
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26211600(104846400); length = 2797/6553600
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.MapTask] - Finished spill 0
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.Task] - Task:attempt_local1425981758_0001_m_000000_0 is done. And is in the process of committing
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.LocalJobRunner] - map
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.Task] - Task 'attempt_local1425981758_0001_m_000000_0' done.
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1425981758_0001_m_000000_0
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1425981758_0001_r_000000_0
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2925e41e
[ INFO :2016-01-22 18:46:00],[org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5565def5
[ INFO :2016-01-22 18:46:01],[org.apache.hadoop.mapreduce.Job] -  map 100% reduce 0%
[ INFO :2016-01-22 18:46:01],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=655097856, maxSingleShuffleLimit=163774464, mergeThreshold=432364608, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[ INFO :2016-01-22 18:46:01],[org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local1425981758_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[ INFO :2016-01-22 18:46:01],[org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local1425981758_0001_m_000000_0 decomp: 3577919 len: 3577923 to MEMORY
[ INFO :2016-01-22 18:46:01],[org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 3577919 bytes from map-output for attempt_local1425981758_0001_m_000000_0
[ INFO :2016-01-22 18:46:01],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 3577919, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3577919
[ INFO :2016-01-22 18:46:01],[org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
[ INFO :2016-01-22 18:46:01],[org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
[ INFO :2016-01-22 18:46:01],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[ INFO :2016-01-22 18:46:02],[org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
[ INFO :2016-01-22 18:46:02],[org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 3577907 bytes
[ INFO :2016-01-22 18:46:02],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 3577919 bytes to disk to satisfy reduce memory limit
[ INFO :2016-01-22 18:46:02],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 3577923 bytes from disk
[ INFO :2016-01-22 18:46:02],[org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
[ INFO :2016-01-22 18:46:02],[org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
[ INFO :2016-01-22 18:46:02],[org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 3577907 bytes
[ INFO :2016-01-22 18:46:02],[org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
[ INFO :2016-01-22 18:46:03],[org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[ INFO :2016-01-22 18:46:04],[org.apache.hadoop.mapred.Task] - Task:attempt_local1425981758_0001_r_000000_0 is done. And is in the process of committing
[ INFO :2016-01-22 18:46:04],[org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
[ INFO :2016-01-22 18:46:04],[org.apache.hadoop.mapred.Task] - Task attempt_local1425981758_0001_r_000000_0 is allowed to commit now
[ INFO :2016-01-22 18:46:04],[org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local1425981758_0001_r_000000_0' to hdfs://10.111.32.202:8020/mysql/raw/spiderdb/sinanews/_temporary/0/task_local1425981758_0001_r_000000
[ INFO :2016-01-22 18:46:04],[org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
[ INFO :2016-01-22 18:46:04],[org.apache.hadoop.mapred.Task] - Task 'attempt_local1425981758_0001_r_000000_0' done.
[ INFO :2016-01-22 18:46:04],[org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1425981758_0001_r_000000_0
[ INFO :2016-01-22 18:46:04],[org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
[ INFO :2016-01-22 18:46:05],[org.apache.hadoop.mapreduce.Job] -  map 100% reduce 100%
[ INFO :2016-01-22 18:46:05],[org.apache.hadoop.mapreduce.Job] - Job job_local1425981758_0001 completed successfully
[ INFO :2016-01-22 18:46:05],[org.apache.hadoop.mapreduce.Job] - Counters: 38
	File System Counters
		FILE: Number of bytes read=7156126
		FILE: Number of bytes written=11204143
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=3568119
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=700
		Map output records=700
		Map output bytes=3575118
		Map output materialized bytes=3577923
		Input split bytes=78
		Combine input records=0
		Combine output records=0
		Reduce input groups=700
		Reduce shuffle bytes=3577923
		Reduce input records=700
		Reduce output records=700
		Spilled Records=1400
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=89
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=441974784
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=3568119
